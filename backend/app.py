from flask import Flask, request, jsonify
from flask_cors import CORS
from scraper.amazon_search_scraper import search_scraping
from scraper.amazon_product_scraper import get_product_info
import scraper.amazon_product_scraper as ps
import openai
import os
import sys
from dotenv import load_dotenv
from urllib.parse import quote_plus

app = Flask(__name__)
CORS(app)

@app.route('/test', methods=['GET'])
def test():
    return jsonify({"message": "Test endpoint working!"})

@app.route('/scrape', methods=['POST'])
def scrape():
    try:
        data = request.json
        print("Received GPT-extracted parameters:", data)
        
        category = data.get('category')
        keywords = data.get('keyword', [])  # Match the frontend's 'keyword' parameter
        max_links_num = data.get('max_links_num', 10)
        
        # Debug logging
        print(f"Category: {category}")
        print(f"Keywords: {keywords}")
        print(f"Max links: {max_links_num}")
        
        search_term = ' '.join(keywords) if isinstance(keywords, list) else str(keywords)
        print(f"Search term: {search_term}")
        
        # URL encode the search terms
        encoded_search = quote_plus(search_term)
        encoded_category = quote_plus(category)
        search_url = f"https://www.amazon.com/s?k={encoded_search}&i={encoded_category}"
        print(f"Generated search URL: {search_url}")
        
        results = search_scraping(
            search_url=search_url,
            category=category,
            keyword=search_term,
            max_links_num=max_links_num
        )
        
        print(f"Scraping results: {results}")  # Debug the results
        
        if not results:
            print("No results returned from scraper")
            return jsonify({
                "status": "success",
                "results": [],
                "message": "No products found"
            })
        
        return jsonify({
            "status": "success",
            "results": results,
            "message": f"Found {len(results)} products"
        })
        
    except Exception as e:
        print(f"Error in scraper endpoint: {str(e)}")
        import traceback
        print(traceback.format_exc())  # Print full stack trace
        return jsonify({
            "error": str(e),
            "message": "Error processing request"
        }), 500

# load_dotenv('.env.backend')
# openai.api_key = os.getenv("Backend_API_KEY")
# OPENAI_MODEL = os.getenv("Backend_MODEL")

# print("OpenAI API Key:", openai.api_key, file=sys.stderr)  # Should not print None
# print("OpenAI Model:", OPENAI_MODEL, file=sys.stderr)      # Should not print None


def get_summary_from_openai(reviews_text):
    """
    Calls the OpenAI API to generate a summary from the given text.
    :param reviews_text: A long text containing customer reviews to be summarized.
    :return: Summary string generated by the OpenAI API.
    """
    load_dotenv('.env.backend')
    # openai.api_key = os.getenv("Backend_API_KEY")
    # OPENAI_MODEL = os.getenv("Backend_MODEL")
    openai.api_key = "sk-svcacct-yDZputh65lu27XG4BcXuT3BlbkFJdcHdCqqnp6GMtfs45Xpp"
    OPENAI_MODEL = "gpt-3.5-turbo"
    print("OpenAI API Key:", openai.api_key, file=sys.stderr)  # Should not print None
    print("OpenAI Model:", OPENAI_MODEL, file=sys.stderr)      # Should not print None
    try:
        response = openai.ChatCompletion.create(
            model=OPENAI_MODEL,
            messages=[
                {"role": "user", "content": f"Summarize these customer reviews into a one-paragraph long overall review:\n{reviews_text}"}
            ],
            max_tokens=150,
            temperature=0.7,
            top_p=1,
            n=1,
            stop=None
        )
        # Extract the summary from the response
        summary = response.choices[0]['message']['content'].strip()
        #print(f"OpenAI Response: {response}")  # Debug print of the entire response
        #print(f"Generated Summary: {summary}")  # Debug print of the summary
        return summary
    except Exception as e:
        print(f"Error calling OpenAI API: {str(e)}", file=sys.stderr)
        return "Unable to generate summary at this time."
    
@app.route('/scrape_summary', methods=['POST'])
def scrapeSummary():
    try:
        # Get the GPT-extracted parameters
        data = request.json
        print("Received GPT-extracted parameters:", data)  # Debug print
        
        # Extract parameters from GPT's JSON format
        ASIN = data.get('ASIN')
        
        # Generate Amazon search URL
        print(f"Generated search URL: {ASIN}")  # Debug print
        
        # Call the scraper
        results = ps.get_product_info(ASIN=ASIN)
        #print(f"Scraped reviews: {results['reviews']}")

        if not results or 'reviews' not in results:
            raise ValueError("No reviews found for the provided ASIN.")
        
        # Extract reviews text and concatenate them
        reviews_text = " ".join([review.get('reviewText', '') for review in results['reviews']])

        # Print the concatenated review text
        #print(f"Reviews text to be summarized: {reviews_text[:500]}...")  # Printing the first 500 characters

        # Use OpenAI API to generate a summary of the reviews
        summary = get_summary_from_openai(reviews_text)
        print(f"Generated Summary: {summary}")  # Debug print

        return jsonify({
            "status": "success",
            "results": summary,
            "message": f"Generated summary for ASIN: {ASIN}"
        })
        
    except Exception as e:
        print(f"Error in scraper endpoint: {str(e)}")
        return jsonify({
            "error": str(e),
            "message": "Error processing request"
        }), 500
    
if __name__ == '__main__':
    app.run(debug=True, port=8000) 